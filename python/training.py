# -*- coding: utf-8 -*-
"""TEST-Untitled0.ipynb

Automatically generated by Colaboratory.

"""

# Import libraries and layers
import os
import numpy as np
from numpy import expand_dims
from numpy import zeros,ones
from numpy.random import randn
from numpy.random import randint
from keras.optimizers import Adam, RMSprop
from keras.layers.advanced_activations import LeakyReLU,ReLU
from keras.models import Sequential
from keras.layers import Dense,Reshape,Flatten,Conv2D,MaxPooling2D,Dropout,BatchNormalization,Conv2DTranspose
import matplotlib.pyplot as plt
import scipy.io
from scipy.io import loadmat
from keras.initializers import RandomNormal
from IPython.display import set_matplotlib_formats
set_matplotlib_formats('png', 'pdf')
!pip install ipython-autotime

os.environ["KERAS_BACKEND"] = "tensorflow"
np.random.seed(10)
Y_noisy=scipy.io.loadmat('In_Data.mat');
Y_noisy = np.array(list(Y_noisy.values())[3])
Channels=scipy.io.loadmat('Out_Data.mat');
Channels = np.array(list(Channels.values())[3])
print(Y_noisy.shape)
print(Channels.shape)

# design discriminator
# The input size if discriminator
Input_shape=(64,8,2)

# Discriminator network structure
def define_discriminator(Input_shape):
    init = RandomNormal(mean=0, stddev=0.02)
    model=Sequential()

    model.add(Conv2D(64,kernel_size=4,strides=2,input_shape=Input_shape,
                             padding='same',kernel_initializer=init))
    model.add(BatchNormalization())
    model.add(LeakyReLU(0.2))
    model.add(Dropout(rate = 0.4))

    model.add(Conv2D(128,kernel_size=4,strides=2,padding='same',kernel_initializer=init))
    model.add(BatchNormalization())
    model.add(LeakyReLU(0.2))
    model.add(Dropout(rate = 0.5))

    model.add(Conv2D(256,kernel_size=4,strides=2,padding='same',kernel_initializer=init))
    model.add(BatchNormalization())
    model.add(LeakyReLU(0.2))
    model.add(Dropout(rate = 0.4))

    model.add(Flatten())
    model.add(Dense(1,activation='linear'))

    model.compile(loss='mean_squared_error',optimizer=Adam(lr=0.0002, beta_1=0.5),
                          metrics=['accuracy'])
    return model
Figure1=define_discriminator(Input_shape)
Figure1.summary()

# design autoencoder as generator
Input = (64,8,2)

# Generator network structure
def define_generator(Input):
    init = RandomNormal(mean=0, stddev=0.02)
    model=Sequential()
    # Encoder
    model.add(Conv2D(128,kernel_size=4,strides=2,input_shape=Input_shape,padding='same',kernel_initializer=init))
    model.add(ReLU(0.2))
    model.add(BatchNormalization())

    model.add(Conv2D(128,kernel_size=4,strides=1,input_shape=Input_shape,padding='same',kernel_initializer=init))
    model.add(ReLU(0.2))
    model.add(BatchNormalization())

    model.add(Conv2D(64,kernel_size=4,strides=2,padding='same',kernel_initializer=init))
    model.add(ReLU(0.2))
    model.add(BatchNormalization())

    model.add(Conv2D(32,kernel_size=4,strides=2,padding='same',kernel_initializer=init))
    model.add(ReLU(0.2))
    model.add(BatchNormalization())


    # Decoder
    model.add(Conv2DTranspose(32,kernel_size=4,strides=2,padding='same',kernel_initializer=init))
    model.add(ReLU(0.2))
    model.add(BatchNormalization())

    model.add(Conv2DTranspose(64,kernel_size=4,strides=1,padding='same',kernel_initializer=init))
    model.add(ReLU(0.2))
    model.add(BatchNormalization())

    model.add(Conv2DTranspose(128,kernel_size=4,strides=2,padding='same',kernel_initializer=init))
    model.add(BatchNormalization())
    model.add(ReLU(0.2))

    model.add(Conv2DTranspose(2,kernel_size=4,strides=2,activation='tanh',padding='same',kernel_initializer=init))
    #generator.compile(loss='binary_crossentropy',optimizer=Adam(lr=0.0002,beta_1=0.5))

    return model
Figure2=define_generator(Input)
Figure2.summary()

# GAN design
Generator=define_generator(Input)
Discriminator=define_discriminator(Input_shape)
def define_GAN(Generator,Discriminator):
    Discriminator.tainable=False
    model=Sequential()
    model.add(Generator)
    model.add(Discriminator)
    model.compile(loss='mean_squared_error',optimizer=Adam(lr=0.0002, beta_1=0.5))
    return model
Figure3=define_GAN(Generator,Discriminator)
Figure3.summary()

# training
def Train(Discriminator, Generator, GAN, Epoch, batch_size):
    # load data
    #Xtrain = np.array([np.array(TrainData[4][ii][0]) for ii in range(len(TrainData[4]))])
    #YTrain = np.array([np.array(TrainData[5][ii][0]) for ii in range(len(TrainData[5]))])
    # add one size to Xtrain
    Y=Y_noisy.reshape(Y_noisy.shape[0],64,8,2)
    H=Channels.reshape(Channels.shape[0],64,8,2)

    #Xtrain=Xtrain.reshape(Xtrain.shape[0],128,400,1)
    Num_Batch=int(Y.shape[0]/batch_size)
    print("Batch per Epoch:",Num_Batch)
    print("Processing:")

    # prepare to save results
    #Rloss=[]
    #Floss=[]
    Raccuracy=list()
    Faccuracy=list()
    Dloss=list()
    #Accuracy=[]
    Gloss=list()


    for i in range(Epoch):
        print("%d " %i, end = '')
        for j in range (Num_Batch):

            # generate label 1 and 0 for real and fake data respectively
            Real_label=np.ones((batch_size,1))
            Fake_label=np.zeros((batch_size,1))

            # calculating loss and accuracy of discriminator on real and fake data
            Ch_index=np.random.randint(0,H.shape[0],batch_size)
            Real_data=H[Ch_index]

            Y_index=np.random.randint(0,Y.shape[0],batch_size)
            Fake=Y[Y_index]
            Fake_data=Generator.predict(Fake)


            Rloss,Racc=Discriminator.train_on_batch(Real_data,Real_label)
            #_,Racc_temp=discriminator.evaluate(Real_data,Real_label, verbose=0)

            Floss,Facc=Discriminator.train_on_batch(Fake_data,Fake_label)
            #_,Facc_temp=discriminator.evaluate(Fake_data,Fake_label, verbose=0)

            d_loss=0.5*np.add(Rloss,Floss)

            # calculating loss of generator and its training
            #discriminator.trainable=False
            Y_index=np.random.randint(0,Y.shape[0],batch_size)
            Fake=Y[Y_index]
            g_loss=GAN.train_on_batch(Fake,Real_label)

            #discriminator.trainable=True

            # show results for each batch size
            #print("%d [Dloss: %f , Racc: %.2f, Facc: %.2f ] [Gloss: %f]" %
            #       (j,d_loss,Racc,Facc,g_loss))

            Dloss.append(d_loss)
            #Accuracy.append((accuracy_temp))
            #Floss.append((Floss_temp))
            Raccuracy.append(Racc)
            Faccuracy.append(Facc)
            Gloss.append(g_loss)

        # save weights of both networks
        Generator.save('generator.h5')
        Discriminator.save('discriminator.h5')
        Generator.save_weights('weightG.h5')
        Discriminator.save_weights('weightsD.h5')

    plt.figure(figsize=(18,4))
    plt.subplot(1,2,1)
    plt.plot(range(Epoch*Num_Batch),Dloss,label='Real')
    plt.plot(range(Epoch*Num_Batch),Gloss,label='Fake')
    plt.xlabel('Batch')
    plt.xlim(0,Epoch*Num_Batch,10)
    plt.ylabel('Loss')
    plt.title('Loss of discriminator and generator')
    plt.legend(prop={"size":18})
    plt.savefig('Loss.pdf')
    plt.show()

    plt.figure(figsize=(18,4))
    plt.subplot(1,2,2)
    plt.plot(range(Epoch*Num_Batch),Raccuracy,label='Real')
    plt.plot(range(Epoch*Num_Batch),Faccuracy,label='Fake')
    plt.xlabel('Batch')
    plt.xlim(0,Epoch*Num_Batch,10)
    plt.ylabel('Accuracy')
    plt.title('Accuracy of discriminator on real and fake data')
    plt.legend(prop={"size":18})
    plt.savefig('Accuracy.pdf')
    plt.show()

#=======================================================
# Training results
#=======================================================
Epoch=200
batch_size=64
Generator=define_generator(Input)
Discriminator=define_discriminator(Input_shape)
GAN=define_GAN(Generator,Discriminator)

Train(Discriminator, Generator, GAN, Epoch, batch_size)
%load_ext autotime
#=======================================================
# Training results
#=======================================================


# uploading trained networks
os.environ["KERAS_BACKEND"] = "tensorflow"
np.random.seed(10)
Attack_Data=scipy.io.loadmat('Test_Data.mat');
Attack_Data = np.array(list(Attack_Data.values())[3])
print(Attack_Data.shape)
Channel_real=scipy.io.loadmat('Test_Channel.mat');
Channel_real = np.array(list(Channel_real.values())[3])
print(Channel_real.shape)

Seed = 0.1
# Load trained networks
from sklearn.metrics import roc_curve, auc, confusion_matrix,accuracy_score
from sklearn.metrics import precision_recall_curve
from keras.models import load_model
from sklearn.metrics import precision_score
from sklearn.metrics import recall_score
from sklearn.metrics import f1_score
from sklearn.preprocessing import MinMaxScaler
import random
import math
import seaborn as sns
#Discriminator=define_discriminator(Input_shape)
#Discriminator=load_model('discriminator.h5')
#Generator=define_generator(Input)
#Generator=load_model('generator.h5')
Estimated_H=Generator.predict(Attack_Data)
realDis=Discriminator.predict(Channel_real)
fakeDis=Discriminator.predict(Estimated_H)

plt.figure(figsize=(4,4))
#plt.subplot(1,2,1)
sns.distplot(realDis, hist=True, kde=True,
             color = 'darkblue',
             hist_kws={'edgecolor':'black'},
             kde_kws={'linewidth': 4},label='Normal Data')
plt.ylabel('Density')
plt.xlabel('Output')
#plt.xlim(-0.1,0.1,0.01)
plt.legend()
plt.savefig('Normal-Abnormal-1.pdf')
plt.figure(figsize=(4,4))
sns.distplot(fakeDis, hist=True, kde=True,
             color = '#E69F00',
             hist_kws={'edgecolor':'#D55E00'},
             kde_kws={'linewidth': 4},label='Abnormal Data')
plt.ylabel('Density')
plt.xlabel('Output')
plt.legend()
plt.savefig('Normal-Abnormal-2.pdf')
#plt.xlim(-0.01,0.01,0.01)
#plt.xlim('')
#plt.hist(realDis['realDis'], color = 'blue', edgecolor = 'black')
#plt.plot(realDis,'o',label='real')
#plt.ylim(-1,1,0.005)
#plt.show()
#plt.figure(figsize=(18,4))
#plt.subplot(1,2,2)
#plt.plot(fakeDis,'o',label='fake')
#plt.ylim(-0.04,0.02,0.005)
#plt.show()
#print(fakeDis)
#print(realDis)

YPredLabel = abs(np.array([realDis, fakeDis]))
YPredLabel[YPredLabel<0.001] = 0
YPredLabel[YPredLabel>=0.001] = 1
YPredLabel.resize(2000,1)
print(YPredLabel)
Ylabel = np.array([ones([1000]), zeros([1000])])
Ylabel.resize(2000,1)
print(Ylabel)
# confusion matri
Accuracy= confusion_matrix(Ylabel, YPredLabel)
precision = precision_score(Ylabel, YPredLabel, average='binary')
recall = recall_score(Ylabel, YPredLabel, average='binary')
score = f1_score(Ylabel, YPredLabel, average='binary')
print(precision)
print(recall)
print(score)
print(accuracy_score(Ylabel, YPredLabel))
print(Accuracy)
fpr, tpr, threshold = roc_curve(Ylabel, YPredLabel)
roc_auc = auc(fpr, tpr)
plt.figure(figsize=(10, 5))
plt.subplot(221)
lw = 2
plt.plot(fpr, tpr, color='darkorange', lw=lw, label='ROC curve (area = %0.2f)' % roc_auc)
plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')
plt.xlim(-0.05,1,0.2)
plt.ylim(-0.05,1,0.2)
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.savefig('ROC1.pdf')
plt.legend()

YPredLabel = abs(np.array([realDis, fakeDis]))
YPredLabel[YPredLabel<0.002] = 0
YPredLabel[YPredLabel>=0.002] = 1
YPredLabel.resize(2000,1)
print(YPredLabel)
Ylabel = np.array([ones([1000]), zeros([1000])])
Ylabel.resize(2000,1)
print(Ylabel)
# confusion matri
Accuracy= confusion_matrix(Ylabel, YPredLabel)
precision = precision_score(Ylabel, YPredLabel, average='binary')
recall = recall_score(Ylabel, YPredLabel, average='binary')
score = f1_score(Ylabel, YPredLabel, average='binary')
print(precision)
print(recall)
print(score)
print(Accuracy)
print(accuracy_score(Ylabel, YPredLabel))
fpr, tpr, threshold = roc_curve(Ylabel, YPredLabel)
roc_auc = auc(fpr, tpr)
plt.figure(figsize=(10, 5))
plt.subplot(221)
lw = 2
plt.plot(fpr, tpr, color='darkorange', lw=lw, label='ROC curve (area = %0.2f)' % roc_auc)
plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')
plt.xlim(-0.05,1,0.2)
plt.ylim(-0.05,1,0.2)
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.savefig('ROC2.pdf')
plt.legend()

YPredLabel = abs(np.array([realDis, fakeDis]))
YPredLabel[YPredLabel<0.003] = 0
YPredLabel[YPredLabel>=0.003] = 1
YPredLabel.resize(2000,1)
print(YPredLabel)
Ylabel = np.array([ones([1000]), zeros([1000])])
Ylabel.resize(2000,1)
print(Ylabel)
# confusion matri
Accuracy= confusion_matrix(Ylabel, YPredLabel)
precision = precision_score(Ylabel, YPredLabel, average='binary')
recall = recall_score(Ylabel, YPredLabel, average='binary')
score = f1_score(Ylabel, YPredLabel, average='binary')
print(precision)
print(recall)
print(score)
print(print(accuracy_score(Ylabel, YPredLabel)))
print(Accuracy)
fpr, tpr, threshold = roc_curve(Ylabel, YPredLabel)
roc_auc = auc(fpr, tpr)

plt.figure(figsize=(10, 5))
plt.subplot(221)
lw = 2
plt.plot(fpr, tpr, color='darkorange', lw=lw, label='ROC curve (area = %0.2f)' % roc_auc)
plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')
plt.xlim(-0.05,1,0.2)
plt.ylim(-0.05,1,0.2)
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.savefig('ROC3.pdf')
plt.legend()

YPredLabel = abs(np.array([realDis, fakeDis]))
YPredLabel[YPredLabel<0.004] = 0
YPredLabel[YPredLabel>=0.004] = 1
YPredLabel.resize(2000,1)
print(YPredLabel)
Ylabel = np.array([ones([1000]), zeros([1000])])
Ylabel.resize(2000,1)
print(Ylabel)
# confusion matri
Accuracy= confusion_matrix(Ylabel, YPredLabel)
precision = precision_score(Ylabel, YPredLabel, average='binary')
recall = recall_score(Ylabel, YPredLabel, average='binary')
score = f1_score(Ylabel, YPredLabel, average='binary')
print(precision)
print(recall)
print(score)
print(print(accuracy_score(Ylabel, YPredLabel)))
print(Accuracy)
fpr, tpr, threshold = roc_curve(Ylabel, YPredLabel)
roc_auc = auc(fpr, tpr)

plt.figure(figsize=(10, 5))
plt.subplot(221)
lw = 2
plt.plot(fpr, tpr, color='darkorange', lw=lw, label='ROC curve (area = %0.2f)' % roc_auc)
plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')
plt.xlim(-0.05,1,0.2)
plt.ylim(-0.05,1,0.2)
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.savefig('ROC4.pdf')
plt.legend()

YPredLabel = abs(np.array([realDis, fakeDis]))
YPredLabel[YPredLabel<0.005] = 0
YPredLabel[YPredLabel>=0.005] = 1
YPredLabel.resize(2000,1)
print(YPredLabel)
Ylabel = np.array([ones([1000]), zeros([1000])])
Ylabel.resize(2000,1)
print(Ylabel)
# confusion matri
Accuracy= confusion_matrix(Ylabel, YPredLabel)
precision = precision_score(Ylabel, YPredLabel, average='binary')
recall = recall_score(Ylabel, YPredLabel, average='binary')
score = f1_score(Ylabel, YPredLabel, average='binary')
print(precision)
print(recall)
print(score)
print(Accuracy)
print(print(accuracy_score(Ylabel, YPredLabel)))
fpr, tpr, threshold = roc_curve(Ylabel, YPredLabel)
roc_auc = auc(fpr, tpr)

plt.figure(figsize=(10, 4))
plt.subplot(221)
lw = 2
plt.plot(fpr, tpr, color='darkorange', lw=lw, label='ROC curve (area = %0.2f)' % roc_auc)
plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')
plt.xlim(-0.05,1,0.2)
plt.ylim(-0.05,1,0.2)
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.savefig('ROC5.pdf')
plt.legend()
